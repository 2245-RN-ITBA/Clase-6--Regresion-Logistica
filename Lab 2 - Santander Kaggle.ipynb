{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Transaction Prediction (KAGGLE)\n",
    "\n",
    "Leer de que trata la competencia\n",
    "\n",
    "https://www.kaggle.com/c/santander-customer-transaction-prediction/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bajada de Dataset\n",
    "La siguiente celda baja el dataset y lo guarda en la carpeta /data.\n",
    "\n",
    "Luego de ejecutarla debería tener los archivos train.csv y test.csv en esta carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "if not os.path.isfile('data/train.csv'):\n",
    "    ! wget https://github.com/lab-pep-itba/santander-kaggle/blob/master/train.csv?raw=true\n",
    "    ! mv train.csv\\?raw\\=true data/train.csv\n",
    "if not os.path.isfile('data/test.csv'):\n",
    "    ! wget https://github.com/lab-pep-itba/santander-kaggle/blob/master/test.csv?raw=true\n",
    "    ! mv test.csv\\?raw\\=true data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Miramos las primeras 5 observaciones del dataset\n",
    "df_train.head()\n",
    "\n",
    "# TODO: Importar datos de test y asignarlos a la variable df_test desde la carpeta data/\n",
    "# df_test  = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
       "       'var_5', 'var_6', 'var_7',\n",
       "       ...\n",
       "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
       "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
       "      dtype='object', length=202)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas features (covariables, variable explicativa, variable independiente, variables exógenas) hay (dimensión de las observaciones, regresoras)? Que columna contiene la salida (variable dependiente, variable endógena)? Cuantas clases hay? Cuantas observaciones tiene train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inspeccionar test\n",
    "# Puede ejecutar los métodos que crea necesarios. Recomendamos describe, columns, shape, head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que columna esta en los datos de train pero no en los de test? Cuantas observaciones de test hay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir data en Train y Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 160_000\n",
    "X_train = df_train.drop(columns=['ID_code', 'target']).values[:N_train]\n",
    "X_val = df_train.drop(columns=['ID_code', 'target']).values[N_train:]\n",
    "y_train = df_train['target'].values[:N_train]\n",
    "y_val = df_train['target'].values[N_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.41 s, sys: 492 ms, total: 9.9 s\n",
      "Wall time: 5.85 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianganzabal/anaconda3/envs/mllab/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A que se debe el warning no termina de convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8507527588341866\n",
      "0.91206875\n"
     ]
    }
   ],
   "source": [
    "acc = model.score(X_train, y_train)\n",
    "auc = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n",
    "print(auc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8527383932243496\n",
      "0.912275\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))\n",
    "print(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuantos parámetros aprendio el modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X_train.mean(axis=0)\n",
    "stds = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = (X_train - means)/stds\n",
    "X_val_normalized = (X_val - means)/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 147 ms, total: 1.25 s\n",
      "Wall time: 847 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = LogisticRegression(solver='lbfgs')\n",
    "%time model_2.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91440625\n",
      "0.8606427353156717\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_train_normalized, y_train))\n",
    "print(roc_auc_score(y_train, model_2.predict_proba(X_train_normalized)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914525\n",
      "0.8629075884886785\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_val_normalized, y_val))\n",
    "print(roc_auc_score(y_val, model_2.predict_proba(X_val_normalized)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,   6,  12,  53, 110,  76,  99, 146, 174,  26,  21,  22,\n",
       "        80, 190, 166, 165, 198,  13,  34, 169,  44,   2, 148,   0,  40,\n",
       "       133, 179, 170,  78,  94,   1, 184, 109,  33, 115,  92,  67, 149,\n",
       "       108, 191, 122, 173, 154,  18,  86, 192, 118, 107, 121, 147,  95,\n",
       "         9,  75,  35, 164, 177, 197, 172,  36, 127,  89, 123, 155,  91,\n",
       "       188,  56,  87,  71,  48,   5,  93, 162, 106, 157, 130, 141, 145,\n",
       "        24, 151,  32, 167, 163, 150, 186, 119,  49,  31, 180,  23, 111,\n",
       "       195,  90, 131, 125, 137, 114, 199,  43, 116, 135,  52,  58, 128,\n",
       "        70, 104, 175, 112, 132, 105,  11, 196,  85,  82, 194,  51,  28,\n",
       "       142,  83,  66, 134, 144, 138,  74,  45, 156,  77,  55,  97, 140,\n",
       "        20,  54, 193,  57,  88, 178,   8, 102, 113,  62,  15, 143, 159,\n",
       "       187, 181, 171,  63,  72,  64,  50,  59, 120, 168, 182, 101,  25,\n",
       "        68,   3,  65, 152,   4,  84,  37,  42, 176,  61, 129,  19, 189,\n",
       "        69,  47,  60,  16,  27,  29,  79,  73, 158,  96, 160,  46, 124,\n",
       "        98,  14, 153, 126,  39, 136, 183, 117,  41, 103, 100, 161,  10,\n",
       "         7, 185,  38,  17,  30])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenamos el valor absoluto de los parámetros de mayor a menor\n",
    "# Coeficientes ordenados en función de su de mayor importancia\n",
    "np.argsort(np.abs(model_2.coef_))[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7,   9,  10,  12,  13,  14,  17,  20,  21,  23,  27,  28,  31,\n",
       "        33,  34,  36,  39,  41,  42,  43,  44,  45,  50,  54,  56,  57,\n",
       "        58,  59,  63,  64,  72,  73,  75,  76,  77,  80,  81,  83,  85,\n",
       "        86,  87,  88,  92,  93,  98, 101, 102, 104, 107, 109, 113, 114,\n",
       "       115, 116, 120, 121, 122, 123, 127, 129, 131, 132, 136, 139, 141,\n",
       "       142, 143, 146, 148, 149, 150, 152, 153, 154, 156, 158, 160, 165,\n",
       "       166, 169, 172, 174, 177, 178, 182, 183, 185, 186, 188, 192, 193,\n",
       "       194, 197, 198])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parámetros menores a cero\n",
    "negative_indexes = np.where(model.coef_<0)[1]\n",
    "negative_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   8,  11,  15,  16,  18,  19,\n",
       "        22,  24,  25,  26,  29,  30,  32,  35,  37,  38,  40,  46,  47,\n",
       "        48,  49,  51,  52,  53,  55,  60,  61,  62,  65,  66,  67,  68,\n",
       "        69,  70,  71,  74,  78,  79,  82,  84,  89,  90,  91,  94,  95,\n",
       "        96,  97,  99, 100, 103, 105, 106, 108, 110, 111, 112, 117, 118,\n",
       "       119, 124, 125, 126, 128, 130, 133, 134, 135, 137, 138, 140, 144,\n",
       "       145, 147, 151, 155, 157, 159, 161, 162, 163, 164, 167, 168, 170,\n",
       "       171, 173, 175, 176, 179, 180, 181, 184, 187, 189, 190, 191, 195,\n",
       "       196, 199])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parámetros mayores a cero\n",
    "positive_indexes = np.where(model.coef_>0)[1]\n",
    "positive_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8867924528301887"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_indexes)/len(positive_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que hay algunos parámetros mayores a cero y otros menores a cero. Como contribuyen en función de su signo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,  12,  76, 146, 174,  21,  80, 166, 165, 198,  13,  34,\n",
       "       169,  44, 148, 109,  33, 115,  92, 149, 108, 122, 154,  86, 192,\n",
       "       107, 121,   9,  75, 177, 197, 172,  36, 127, 123, 188,  56,  87,\n",
       "        93, 141, 150, 186,  31,  23, 131, 114,  43, 116,  58, 104, 132,\n",
       "        85, 194,  28, 142,  83,  45, 156,  77,  20,  54, 193,  57,  88,\n",
       "       178, 102, 113, 143,  63,  72,  64,  50,  59, 120, 182, 101,  68,\n",
       "       152,  42, 129,  27,  73, 158, 160,  98,  14, 153,  39, 136, 183,\n",
       "        41, 103,  10,   7, 185,  38,  17,  30, 161, 100, 117, 126, 124,\n",
       "        46,  96,  79,  29,  16,  60,  47,  69, 189,  19,  61, 176,  37,\n",
       "        84,   4,  65,   3,  25, 168, 171, 181, 187, 159,  15,  62,   8,\n",
       "       140,  97,  55,  74, 138, 144, 134,  66,  51,  82, 196,  11, 105,\n",
       "       112, 175,  70, 128,  52, 135, 199, 137, 125,  90, 195, 111, 180,\n",
       "        49, 119, 163, 167,  32, 151,  24, 145, 130, 157, 106, 162,   5,\n",
       "        48,  71,  91, 155,  89, 164,  35,  95, 147, 118,  18, 173, 191,\n",
       "        67, 184,   1,  94,  78, 170, 179, 133,  40,   0,   2, 190,  22,\n",
       "        26,  99, 110,  53,   6])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenados de menor a mayor\n",
    "np.argsort(model_2.coef_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,  53, 110,  99,  26,  22, 190,   2,   0,  40, 133, 179, 170,\n",
       "        78,  94,   1, 184,  67, 191, 173,  18, 118, 147,  95,  35, 164,\n",
       "        89, 155,  91,  71,  48,   5, 162, 106, 157, 130, 145,  24, 151,\n",
       "        32, 167, 163, 119,  49, 180, 111, 195,  90, 125, 137, 199, 135,\n",
       "        52, 128,  70, 175, 112, 105,  11, 196,  82,  51,  66, 134, 144,\n",
       "       138,  74,  55,  97, 140,   8,  62,  15, 159, 187, 181, 171, 168,\n",
       "        25,   3,  65,   4,  84,  37, 176,  61,  19, 189,  69,  47,  60,\n",
       "        16,  29,  79,  96,  46, 124, 126, 117, 100, 161,  30,  17,  38,\n",
       "       185,   7,  10, 103,  41, 183, 136,  39, 153,  14,  98, 160, 158,\n",
       "        73,  27, 129,  42, 152,  68, 101, 182, 120,  59,  50,  64,  72,\n",
       "        63, 143, 113, 102, 178,  88,  57, 193,  54,  20,  77, 156,  45,\n",
       "        83, 142,  28, 194,  85, 132, 104,  58, 116,  43, 114, 131,  23,\n",
       "        31, 186, 150, 141,  93,  87,  56, 188, 123, 127,  36, 172, 197,\n",
       "       177,  75,   9, 121, 107, 192,  86, 154, 122, 108, 149,  92, 115,\n",
       "        33, 109, 148,  44, 169,  34,  13, 198, 165, 166,  80,  21, 174,\n",
       "       146,  76,  12, 139,  81])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenados de mayor a menor\n",
    "np.argsort(model_2.coef_)[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos correlación de cada variable con la salida\n",
    "correlations = []\n",
    "for i in range(200):\n",
    "    correlations.append(np.corrcoef(y_train, X_train_normalized[:,i])[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,  12, 110,   6,  26,  53, 146, 174,  76,  99,  80, 166,\n",
       "        22, 165,  21, 190, 148,   2,  13,  34, 133,   0, 198, 169, 109,\n",
       "       179,  44,  40,   1, 115, 149, 170, 184,  78,  94,  92, 108,  67,\n",
       "       191,  33,  18, 154, 173,  86, 122, 192, 147, 118,   9, 121,  75,\n",
       "        95, 164, 123,  35,  91,  36, 172, 127, 107, 155,  89, 177, 197,\n",
       "        56,  93, 188,  87,  71, 162,  48, 157, 106, 141, 145,   5,  32,\n",
       "       163, 131, 167, 186, 119,  49,  24, 151, 130,  90, 111, 135, 180,\n",
       "       125,  43,  51, 114, 195, 199,  52,  23, 150,  31, 116,  85,  70,\n",
       "       137, 105, 128, 104,  58, 112, 196, 132,  11,  28, 175,  66,  82,\n",
       "       194, 156,  83, 142,  45, 144,  88,  74, 178, 138,  77,   8,  97,\n",
       "       134,  20,  55, 193,  54,  15, 102,  57, 159, 140, 171,  62, 113,\n",
       "       187,  63, 143,  64,  25, 181,  50, 120, 168,  59,   3,  72,  65,\n",
       "        68,  84, 101,  19,   4,  37,  61,  69, 189, 152, 182,  42,  16,\n",
       "       129, 176,  47,  79, 153,  14, 183,  46, 160,  73,  60,  98, 158,\n",
       "       124,  27, 100,  96,  29,  39,  10, 117, 136,   7,  41, 103,  38,\n",
       "       161, 185,  30, 126,  17])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(correlations))[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos 200 columnas con el cuadrado de cada columna normaliado a train\n",
    "X_train_sq = X_train_normalized**2\n",
    "means_sq = X_train_sq.mean(axis=0)\n",
    "stds_sq = X_train_sq.std(axis=0)\n",
    "X_train_FE = np.append(X_train_normalized, (X_train_sq - means_sq)/stds_sq, axis=1)\n",
    "\n",
    "# Agregamos el cuadrado a validación normalizando con la media y std obtenida en train\n",
    "X_val_sq = X_val_normalized**2\n",
    "X_val_FE = np.append(X_val_normalized, (X_val_normalized**2-means_sq)/stds_sq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 s, sys: 245 ms, total: 2.35 s\n",
      "Wall time: 1.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = LogisticRegression(solver='lbfgs')\n",
    "%time model_3.fit(X_train_FE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9218625\n",
      "0.8910807326950416\n"
     ]
    }
   ],
   "source": [
    "print(model_3.score(X_train_FE, y_train))\n",
    "print(roc_auc_score(y_train, model_3.predict_proba(X_train_FE)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221\n",
      "0.8927208962331821\n"
     ]
    }
   ],
   "source": [
    "print(model_3.score(X_val_FE, y_val))\n",
    "print(roc_auc_score(y_val, model_3.predict_proba(X_val_FE)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139,  81,   6,  53,  12,  21,  76, 174, 110,  34, 146,  26, 169,\n",
       "        99, 165, 281,  22, 166, 190,  78,  33,  40,  13, 170, 149,  80,\n",
       "       148, 184,  94, 109, 133, 192,  92, 122, 115,  67, 121, 198,   0,\n",
       "         1, 173, 179,   2, 212,  18, 118, 108, 253, 398, 107, 191, 172,\n",
       "       177,  44, 154, 310, 164,  35, 197, 226, 188,  36, 339, 299,  75,\n",
       "       147, 244,   9, 280,  86,  87, 366,  95,  89,  48, 390, 127,  91,\n",
       "       222, 309,  71, 346, 155, 202,   5, 323, 374, 379,  56, 145, 106,\n",
       "       162, 123, 206, 221,  32, 186, 141, 200, 150, 348, 151,  31, 365,\n",
       "       199,  49, 130, 240,  23, 278, 167, 157,  24, 333,  90, 276,  93,\n",
       "       111, 119, 354, 137, 364, 195, 286, 363, 128, 112, 180, 380,  52,\n",
       "       104, 114,  58, 131,  70, 355, 116, 125, 135, 295, 370, 233, 391,\n",
       "       292, 201,  43, 275, 175, 196, 293, 357, 388, 294,  85, 163, 213,\n",
       "       347,  82, 308, 142, 132,  28, 105,  11, 319, 234, 194, 291,  74,\n",
       "       205,  97,  77, 140, 315,  45, 322,  20, 369,  55, 267, 256, 287,\n",
       "       156,  66, 289, 251, 144,  51,  54, 306, 332,  83, 377, 397, 321,\n",
       "       138, 134, 384, 330, 243, 218, 335,  57, 362, 341,   8,  88, 232,\n",
       "       345, 102, 314, 113, 178, 193, 372, 159, 307, 325, 209, 250, 331,\n",
       "       235, 373, 395, 367, 236, 311, 249, 396, 143, 288, 258, 252, 269,\n",
       "       187,  62, 318,  59, 327, 271,  64,  15, 368, 171, 349,  72, 312,\n",
       "       260,  63, 120, 350, 334, 211, 101,  50, 371, 375, 328, 168, 393,\n",
       "       394, 268,   4, 352, 262, 338, 351,  65,  84, 344, 181, 176, 228,\n",
       "       386, 283, 272, 343, 216, 337, 387,  42, 152, 282, 215, 189, 182,\n",
       "         3, 270, 248,  37, 219,  25, 305,  68,  19, 353, 290, 129, 279,\n",
       "       381, 285,  61, 378, 302, 298, 297, 263, 336, 203, 266, 246, 223,\n",
       "       356, 277, 316, 239, 342, 241,  69, 208, 204,  29, 304, 392,  47,\n",
       "        96, 301, 225, 383, 399, 313, 255, 153, 259, 324, 326, 160, 265,\n",
       "       238, 245, 158, 261, 224,  16, 136,  39, 126,  41,  27, 376, 329,\n",
       "        73,  60, 242, 317, 227, 124,  46,  79, 360,  14, 183, 257,  98,\n",
       "       229, 303, 237, 296, 264, 274, 103, 273, 359, 320, 210, 361, 300,\n",
       "       185, 389, 385, 247, 214, 284, 161, 217, 358, 207, 100, 340, 220,\n",
       "        38, 382, 230,  17, 231,   7,  10, 117, 254,  30])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coeficientes ordenados en función de su de mayor importancia\n",
    "np.argsort(np.abs(model_3.coef_))[0][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  8.22it/s]\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "aucs = []\n",
    "val_predictions = np.zeros((len(X_val_normalized), 200))\n",
    "train_predictions = np.zeros((len(X_train_normalized), 200))\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    model_ind = LogisticRegression(solver='lbfgs')\n",
    "    X_one_train = X_train_normalized[:,i].reshape(-1,1)\n",
    "    # X_one_train = np.array([X_train_normalized[:,i], X_train_normalized[:,i]**2]).T\n",
    "    model_ind.fit(X_one_train, y_train)\n",
    "    X_one_val = X_val_normalized[:,i].reshape(-1,1)\n",
    "    # X_one_val = np.array([X_val_normalized[:,i], X_val_normalized[:,i]**2]).T\n",
    "    train_predictions[:, i] = model_ind.predict_proba(X_one_train)[:,1]\n",
    "    val_predictions[:, i] = model_ind.predict_proba(X_one_val)[:,1]\n",
    "    acc = model_ind.score(X_one_val, y_val)\n",
    "    auc = roc_auc_score(y_val, val_predictions[:, i])\n",
    "    accs.append(acc)\n",
    "    aucs.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692585548756987"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, train_predictions.sum(axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8729094090424484"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_predictions.sum(axis=1)) \n",
    "# 0.8729094090424484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
