{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizadores\n",
    "\n",
    "Analizaremos distintas formas de minimizar la función de costo de una red neuronal o un regresor logístico o lineal.\n",
    "\n",
    "Para mas información se recomienda la lectura de este [paper](https://arxiv.org/pdf/1609.04747.pdf)\n",
    "\n",
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos encontrar los valores de los parámetros que minimizan la función de costo.\n",
    "Una alternativa es encontrar el mínimo de la función de costo iterativamente. Esto lo podemos hacer basándonos en los siguientes conceptos:\n",
    "\n",
    "* Inicializamos los parámetros del modelo con un valor aleatorio: $\\mathbf{\\omega}(0)$\n",
    "* El gradiente de la función de costo evaluado en un punto particular, nos dará la dirección de máxima variación de la función de costo. Es decir, si yo muevo al vector de parámetros en la dirección de máxima variación, el valor de la función de costo subirá a la tasa mas alta posible.\n",
    "* Al contrario, si muevo al vector de parámetros en la dirección contraria, el valor de la función de costo bajará a la tasa mas alta posible: \n",
    "* Muevo los pesos muy poco en la dirección contraria a la del gradiente y vuelvo a calcular el gradiente en ese punto. $\\mathbf{\\omega}(k+1)=\\mathbf{\\omega}(k)-2\\alpha\\nabla(J(\\mathbf{\\omega}))$.\n",
    "* Podemos terminar este proceso iterativo cuando $J$ sea mas chico que un valor deseado, o luego de un número de iteraciones fijo.\n",
    "\n",
    "<img src=\"grad.png\" alt=\"Mountain View\" style=\"width:600px;height:400px;\">\n",
    "\n",
    "A este proceso para hallar el mínimo de una función se lo conoce como Batch Gradient Descent.\n",
    "Para cada peso en particular, lo podemos actualizar como:\n",
    "\n",
    "$$\\omega_1(k+1)=\\omega_i(k)-\\alpha\\frac{1}{N}\\sum_{j=0}^N( \\omega \\mathbf x^{(j)}-y^{(j)})x^{(j)}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "Stochastic Gradient Descent es una simplificación de Batch Gradient Descent.\n",
    "La misma consiste en reemplazar la función de costo total (la cual es el error cuadrático medio calculado para todo el set de muestras) por el error cuadrático instantáneo. Si hacemos esto, las ecuaciones de actualización de los pesos nos quedarán:\n",
    "\n",
    "$$\\omega_i(k+1)=\\omega_i(k)-\\alpha ( \\omega \\mathbf x^{(k)}-y^{(k)})x^{(k)}_i$$\n",
    "\n",
    "El criterio de corte podrá ser por cantidad de iteraciones, o si el errór cuadrático instantáneo de todo un batch se mantiene por debajo de un valor predeterminado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibach gradient descent (muchas veces se incluye dentro de SGD)\n",
    "\n",
    "Hemos visto cómo encontrar el mínimo de la superficie de error en forma iterativa de dos formas:\n",
    "\n",
    "- Desde la ecuación del MSE (considerando todas las observaciones), moviendo los pesos paso a paso en dirección opuesta al gradiente de la superficie del error.(Batch-GD). Este método tiene mucho cálculo ya que para cada movimiento de los pesos hay que recalcular el gradiente en base al error de todas las muestras.\n",
    "- Desde el error instantáneo (considerando una sola observación), moviendo los pesos en dirección opuesta al gradiente del error instantáneo, tomando una observación distinta a cada paso. (SGD). Este método tiene \n",
    "\n",
    "<img src=\"stochastic-vs-batch-gradient-descent.png\" alt=\"Mountain View\" style=\"width:600px;height:400px;\">\n",
    "\n",
    "\n",
    "La solución provista por el primer método es mas estable ya que trabaja directamente con el gradiente de la superficie del MSE.  \n",
    "El segundo método es mas ruidoso ya que solo tiene en cuenta el error instantáneo y opera sobre el supuesto de que para una gran cantidad de iteraciones, con un epsilon muy chico, se llegará al mismo mínimo que con el método anterior. En muchas iteraciones los pesos podrían moverse en dirección incluso opuesta al valor buscado. \n",
    "\n",
    "Una opción intermedia entre ambos métodos es utilizar el método llamado minibatch-GD. El mismo consiste en trabajar con el error cuadrático correspondiente a un número parcial de observaciones (algún número en el medio entre la totalidad de las observaciones y una sola observación). \n",
    "\n",
    "En definitiva todos los métodos se basan en la misma ecuación:\n",
    "\n",
    "$$\\omega_i(k+1)=\\omega_i(k)-\\alpha\\frac{1}{N}\\sum_{j=0}^N( \\omega \\mathbf x^{(j)}-y^{(j)})x^{(j)}_i$$\n",
    "\n",
    "con:\n",
    "\n",
    "BGD: N=cantidad de observaciones  \n",
    "SGD: N=1  \n",
    "MBGD: 1<N<cantidad de observaciones  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "83px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
